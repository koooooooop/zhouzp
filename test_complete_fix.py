#!/usr/bin/env python3
import torch
import sys
import os
sys.path.append('.')

def test_complete_fix():
    print("ğŸ”§ æµ‹è¯•å®Œæ•´ä¿®å¤...")
    
    # è®¾å¤‡è®¾ç½®
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ”¥ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # 1. é…ç½®éªŒè¯å’Œä¿®å¤
    print("ğŸ“‹ éªŒè¯é…ç½®æ–‡ä»¶...")
    import yaml
    
    # åˆ›å»ºé…ç½®éªŒè¯å™¨
    def validate_and_fix_config(config):
        # ç¡®ä¿åŸºç¡€ç»“æ„å­˜åœ¨
        if 'data' not in config:
            config['data'] = {}
        if 'model' not in config:
            config['model'] = {}
        if 'training' not in config:
            config['training'] = {}
        
        # ä¿®å¤dataé…ç½®
        data_defaults = {
            'batch_size': 16,
            'num_workers': 2,
            'pin_memory': True,
            'train_ratio': 0.7,
            'val_ratio': 0.2,
            'test_ratio': 0.1,
            'scaler_type': 'standard',
            'normalize': True,
            'seq_len': 96,
            'pred_len': 96
        }
        
        for key, default_value in data_defaults.items():
            if key not in config['data']:
                config['data'][key] = default_value
        
        # ä¿®å¤modelé…ç½®
        model_defaults = {
            'input_dim': 21,
            'output_dim': 21,
            'hidden_dim': 64,
            'num_experts': 4,
            'seq_len': config['data']['seq_len'],
            'pred_len': config['data']['pred_len'],
            'top_k': 2,
            'embedding_dim': 128,
            'temperature': {
                'initial': 5.0,
                'min': 1.0,
                'max': 10.0,
                'decay_rate': 0.995
            },
            'flow': {
                'num_layers': 4,
                'hidden_dim': 32,
                'latent_dim': 256,
                'use_pretrained': True
            }
        }
        
        for key, default_value in model_defaults.items():
            if key not in config['model']:
                config['model'][key] = default_value
        
        # è®¡ç®—Flowæ¨¡å‹çš„input_dim
        if 'input_dim' not in config['model']['flow']:
            config['model']['flow']['input_dim'] = config['data']['seq_len'] * config['model']['input_dim']
        
        # ä¿®å¤trainingé…ç½®
        training_defaults = {
            'epochs': 30,
            'learning_rate': 0.0001,
            'optimizer': 'adamw',
            'weight_decay': 0.01,
            'gradient_clip': 0.5,
            'scheduler': 'cosine',
            'loss_weights': {
                'prediction': 1.0,
                'reconstruction': 0.1,
                'triplet': 0.1
            },
            'triplet_margin': 0.5,
            'triplet_mining': 'batch_hard'
        }
        
        for key, default_value in training_defaults.items():
            if key not in config['training']:
                config['training'][key] = default_value
        
        # ç¡®ä¿batch_sizeåœ¨ä¸¤ä¸ªåœ°æ–¹éƒ½æœ‰
        if 'batch_size' not in config['training']:
            config['training']['batch_size'] = config['data']['batch_size']
        
        # æ·»åŠ deviceé…ç½®
        config['device'] = str(device)
        
        return config
    
    with open('configs/weather_stable.yaml', 'r') as f:
        config = yaml.safe_load(f)
    
    config = validate_and_fix_config(config)
    print("âœ… é…ç½®éªŒè¯é€šè¿‡")
    
    # 2. æµ‹è¯•æ•°æ®åŠ è½½
    print("ğŸ“Š æµ‹è¯•æ•°æ®åŠ è½½...")
    from data.universal_dataset import UniversalDataModule
    
    try:
        data_module = UniversalDataModule(config)
        train_loader = data_module.get_train_loader()
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {len(train_loader)} batches")
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # 3. æµ‹è¯•æ¨¡å‹åˆ›å»º
    print("ğŸ¤– æµ‹è¯•æ¨¡å‹åˆ›å»º...")
    from models.m2_moep import M2_MOEP
    
    try:
        model = M2_MOEP(config)
        
        # é‡è¦ï¼šå°†æ¨¡å‹ç§»åŠ¨åˆ°æ­£ç¡®çš„è®¾å¤‡
        model = model.to(device)
        print(f"âœ… æ¨¡å‹ç§»åŠ¨åˆ°è®¾å¤‡: {device}")
        
        print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ: {sum(p.numel() for p in model.parameters())} parameters")
        print(f"âœ… æ¨¡å‹é…ç½®ä¿å­˜æˆåŠŸ: configå­˜åœ¨ = {hasattr(model, 'config')}")
        print(f"âœ… top_ké…ç½®: {getattr(model, 'top_k', 'None')}")
        
        # éªŒè¯æ¨¡å‹è®¾å¤‡
        model_device = next(model.parameters()).device
        print(f"âœ… æ¨¡å‹å®é™…è®¾å¤‡: {model_device}")
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # 4. æµ‹è¯•æŸå¤±å‡½æ•°
    print("ğŸ“‰ æµ‹è¯•æŸå¤±å‡½æ•°...")
    from utils.losses import CompositeLoss
    
    try:
        criterion = CompositeLoss(config)
        print("âœ… æŸå¤±å‡½æ•°åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        print(f"âŒ æŸå¤±å‡½æ•°åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # 5. æµ‹è¯•å®Œæ•´çš„è®­ç»ƒæ­¥éª¤
    print("ğŸƒ æµ‹è¯•å®Œæ•´è®­ç»ƒæ­¥éª¤...")
    
    try:
        for batch_data in train_loader:
            if len(batch_data) == 2:
                batch_x, batch_y = batch_data
                
                # é‡è¦ï¼šå°†æ•°æ®ç§»åŠ¨åˆ°æ­£ç¡®çš„è®¾å¤‡
                batch_x = batch_x.to(device)
                batch_y = batch_y.to(device)
                
                print(f"âœ… æ•°æ®è§£åŒ…æˆåŠŸ: {batch_x.shape}, {batch_y.shape}")
                print(f"âœ… æ•°æ®è®¾å¤‡: {batch_x.device}")
            else:
                print(f"âŒ æ•°æ®æ ¼å¼é”™è¯¯: {len(batch_data)}")
                return False
            
            # æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­
            model.eval()
            with torch.no_grad():
                output = model(batch_x, ground_truth=batch_y, return_aux_info=True)
                predictions = output['predictions']
                aux_info = output['aux_info']
            
            # æ£€æŸ¥å¿…è¦çš„å­—æ®µ
            required_fields = ['expert_weights', 'expert_embeddings']
            for field in required_fields:
                if field not in aux_info:
                    print(f"âŒ ç¼ºå°‘å­—æ®µ: {field}")
                    print(f"å®é™…å­—æ®µ: {list(aux_info.keys())}")
                    return False
            
            print(f"âœ… æ¨¡å‹å‰å‘ä¼ æ’­æˆåŠŸ: {predictions.shape}")
            print(f"âœ… é¢„æµ‹è¾“å‡ºè®¾å¤‡: {predictions.device}")
            print(f"âœ… è¾…åŠ©ä¿¡æ¯å­—æ®µ: {list(aux_info.keys())}")
            
            # æµ‹è¯•æŸå¤±è®¡ç®—
            losses = criterion(
                predictions=predictions,
                targets=batch_y,
                expert_weights=aux_info.get('expert_weights'),
                expert_embeddings=aux_info.get('expert_embeddings'),
                flow_embeddings=None,
                flow_log_det=aux_info.get('flow_log_det')
            )
            
            print(f"âœ… æŸå¤±è®¡ç®—æˆåŠŸ: {losses['total']:.4f}")
            print(f"  - é¢„æµ‹æŸå¤±: {losses['prediction']:.4f}")
            print(f"  - é‡æ„æŸå¤±: {losses['reconstruction']:.4f}")
            print(f"  - ä¸‰å…ƒç»„æŸå¤±: {losses['triplet']:.4f}")
            break
    except Exception as e:
        print(f"âŒ è®­ç»ƒæ­¥éª¤æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    print("ğŸ‰ æ‰€æœ‰ä¿®å¤éªŒè¯é€šè¿‡!")
    return True

if __name__ == "__main__":
    success = test_complete_fix()
    exit(0 if success else 1)