#!/usr/bin/env python3
"""
MÂ²-MOEP vs Autoformer æ€§èƒ½æ¯”è¾ƒå®éªŒ
=================================

æœ¬è„šæœ¬æŒ‰ç…§Autoformerè®ºæ–‡çš„æ ‡å‡†å®éªŒè®¾ç½®è¿›è¡Œæ€§èƒ½æ¯”è¾ƒå®éªŒã€‚

æ•°æ®é›†ï¼š
- ETTh1, ETTh2, ETTm1, ETTm2 (Electricity Transformer Temperature)
- Weather (å¤©æ°”æ•°æ®)
- Electricity (ç”µåŠ›æ¶ˆè´¹æ•°æ®)
- Traffic (äº¤é€šæ•°æ®)
- Exchange Rate (æ±‡ç‡æ•°æ®)
- ILI (æµæ„Ÿæ•°æ®)

å®éªŒè®¾ç½®ï¼š
- è¾“å…¥åºåˆ—é•¿åº¦: 96
- é¢„æµ‹é•¿åº¦: 96, 192, 336, 720
- è¯„ä¼°æŒ‡æ ‡: MSE, MAE
"""

import os
import sys
import json
import time
import yaml
import torch
import numpy as np
import pandas as pd
from datetime import datetime
from typing import Dict, List, Tuple
import argparse
import logging

from train import M2MOEPTrainer
from configs.config_generator import ConfigGenerator
from utils.metrics import calculate_metrics


class AutoformerComparisonExperiment:
    """Autoformeræ¯”è¾ƒå®éªŒç±»"""
    
    def __init__(self, base_config: Dict = None):
        self.base_config = base_config or {}
        self.results_dir = 'autoformer_comparison_results'
        os.makedirs(self.results_dir, exist_ok=True)
        
        # è®¾ç½®æ—¥å¿—
        self.setup_logging()
        
        # Autoformeræ ‡å‡†å®éªŒè®¾ç½®
        self.autoformer_datasets = {
            'ETTh1': {
                'path': 'dataset/ETT-small_7ä¸ªå› ç´ çš„å˜å‹å™¨æ¸©åº¦å˜åŒ–/ETTh1.csv',
                'target': 'OT',  # ç›®æ ‡å˜é‡
                'features': 'M',  # Multivariate
                'freq': 'h'  # å°æ—¶çº§åˆ«
            },
            'ETTh2': {
                'path': 'dataset/ETT-small_7ä¸ªå› ç´ çš„å˜å‹å™¨æ¸©åº¦å˜åŒ–/ETTh2.csv',
                'target': 'OT',
                'features': 'M',
                'freq': 'h'
            },
            'ETTm1': {
                'path': 'dataset/ETT-small_7ä¸ªå› ç´ çš„å˜å‹å™¨æ¸©åº¦å˜åŒ–/ETTm1.csv',
                'target': 'OT',
                'features': 'M',
                'freq': 't'  # 15åˆ†é’Ÿçº§åˆ«
            },
            'ETTm2': {
                'path': 'dataset/ETT-small_7ä¸ªå› ç´ çš„å˜å‹å™¨æ¸©åº¦å˜åŒ–/ETTm2.csv',
                'target': 'OT',
                'features': 'M',
                'freq': 't'
            },
            'Weather': {
                'path': 'dataset/weather_æ°”è±¡ç«™_21ä¸ªæ°”è±¡å› å­/weather.csv',
                'target': 'OT',
                'features': 'M',
                'freq': 't'
            },
            'Electricity': {
                'path': 'dataset/electricity_321ä¸ªå®¢æˆ·çš„æ¯å°æ—¶ç”¨ç”µé‡/electricity.csv',
                'target': 'MT_320',  # é€šå¸¸æ˜¯æœ€åä¸€åˆ—
                'features': 'M',
                'freq': 'h'
            },
            'Traffic': {
                'path': 'dataset/traffic_862ä¸ªä¼ æ„Ÿå™¨æµ‹é‡çš„æ¯å°æ—¶é“è·¯å ç”¨ç‡/traffic.csv',
                'target': 'Sensor_861',  # é€šå¸¸æ˜¯æœ€åä¸€åˆ—
                'features': 'M',
                'freq': 'h'
            },
            'Exchange': {
                'path': 'dataset/exchange_rate_8ä¸ªå›½å®¶çš„æ±‡ç‡å˜åŒ–/exchange_rate.csv',
                'target': 'OT',
                'features': 'M',
                'freq': 'd'  # æ—¥çº§åˆ«
            },
            'ILI': {
                'path': 'dataset/illness_æµæ„Ÿæ‚£è€…æ¯”ä¾‹å’Œæ•°é‡/national_illness.csv',
                'target': '%ILI',
                'features': 'M',
                'freq': 'w'  # å‘¨çº§åˆ«
            }
        }
        
        # Autoformeræ ‡å‡†é¢„æµ‹é•¿åº¦
        self.prediction_lengths = [96, 192, 336, 720]
        
        # å›ºå®šçš„è¾“å…¥åºåˆ—é•¿åº¦ï¼ˆæŒ‰Autoformerè®ºæ–‡ï¼‰
        self.input_length = 96
        
        # å®éªŒç»“æœå­˜å‚¨
        self.all_results = {}
        
    def setup_logging(self):
        """è®¾ç½®å®éªŒæ—¥å¿—"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        log_file = os.path.join(self.results_dir, f'autoformer_comparison_{timestamp}.log')
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler(sys.stdout)
            ]
        )
        
        self.logger = logging.getLogger(__name__)
        self.logger.info("=" * 80)
        self.logger.info("ğŸš€ MÂ²-MOEP vs Autoformer æ€§èƒ½æ¯”è¾ƒå®éªŒå¼€å§‹")
        self.logger.info("=" * 80)
    
    def generate_autoformer_config(self, dataset_name: str, pred_len: int) -> Dict:
        """
        ç”Ÿæˆç¬¦åˆAutoformerå®éªŒè®¾ç½®çš„é…ç½®
        
        Args:
            dataset_name: æ•°æ®é›†åç§°
            pred_len: é¢„æµ‹é•¿åº¦
            
        Returns:
            å®éªŒé…ç½®å­—å…¸
        """
        dataset_info = self.autoformer_datasets[dataset_name]
        
        # åŸºç¡€é…ç½®
        config = {
            'data': {
                'dataset_name': dataset_name.lower(),
                'data_path': dataset_info['path'],
                'target': dataset_info['target'],
                'features': dataset_info['features'],
                'seq_len': self.input_length,
                'pred_len': pred_len,
                'batch_size': 32,  # Autoformeræ ‡å‡†æ‰¹æ¬¡å¤§å°
                'num_workers': 4,
                'train_ratio': 0.7,
                'val_ratio': 0.2,
                'test_ratio': 0.1,
                'standardization': 'standard'
            },
            'model': {
                'input_dim': 21,  # ä¼šæ ¹æ®å®é™…æ•°æ®è°ƒæ•´
                'hidden_dim': 512,  # å¢å¤§éšè—ç»´åº¦ä»¥åŒ¹é…Autoformer
                'output_dim': 21,
                'num_experts': 8,  # å¢åŠ ä¸“å®¶æ•°é‡
                'seq_len': self.input_length,
                'pred_len': pred_len,
                'embedding_dim': 512,
                
                # ä¸“å®¶ç½‘ç»œé…ç½®
                'expert_params': {
                    'mamba_d_model': 512,  # å¢å¤§Mambaæ¨¡å‹ç»´åº¦
                    'mamba_scales': [1, 2, 4, 8],  # æ›´å¤šå°ºåº¦
                    'mamba_d_state': 32,  # å¢å¤§çŠ¶æ€ç»´åº¦
                    'mamba_d_conv': 8,
                    'mamba_expand': 4
                },
                
                # Flowæ¨¡å‹é…ç½®
                'flow': {
                    'latent_dim': 256,
                    'use_pretrained': True,
                    'num_coupling_layers': 8
                },
                
                # æ¸©åº¦è°ƒåº¦é…ç½®
                'temperature': {
                    'initial': 1.0,
                    'min': 0.1,
                    'max': 5.0,
                    'decay': 0.95,
                    'schedule': 'adaptive'
                },
                
                # å¤šæ ·æ€§é…ç½®
                'diversity': {
                    'prototype_dim': 128,
                    'num_prototypes': 16,
                    'diversity_weight': 0.1,
                    'force_diversity': True
                },
                
                # ä¸‰å…ƒç»„æŸå¤±é…ç½®
                'triplet': {
                    'margin': 0.5,
                    'mining_strategy': 'batch_hard',
                    'loss_weight': 0.1,
                    'performance_window': 100
                }
            },
            'training': {
                'epochs': 100,  # å……åˆ†è®­ç»ƒ
                'learning_rate': 0.0001,  # è¾ƒå°çš„å­¦ä¹ ç‡
                'weight_decay': 1e-4,
                'batch_size': 32,
                'gradient_clip': 1.0,
                'patience': 20,
                'save_interval': 10,
                'min_lr': 1e-6,
                
                # æŸå¤±æƒé‡é…ç½®
                'loss_weights': {
                    'prediction': 1.0,
                    'reconstruction': 0.1,
                    'triplet': 0.1,
                    'consistency': 0.05,
                    'load_balance': 0.01
                },
                
                # Flowæ¨¡å‹è·¯å¾„
                'flow_model_path': f'flow_model_{dataset_name.lower()}_{pred_len}.pth'
            },
            'experiment': {
                'name': f'M2MOEP_vs_Autoformer_{dataset_name}_{pred_len}',
                'description': f'MÂ²-MOEPåœ¨{dataset_name}æ•°æ®é›†ä¸Šé¢„æµ‹é•¿åº¦{pred_len}çš„æ€§èƒ½',
                'dataset': dataset_name,
                'prediction_length': pred_len,
                'comparison_baseline': 'Autoformer'
            },
            'save_dir': os.path.join(self.results_dir, f'{dataset_name}_{pred_len}'),
            'seed': 42
        }
        
        return config
    
    def run_single_experiment(self, dataset_name: str, pred_len: int) -> Dict:
        """
        è¿è¡Œå•ä¸ªæ•°æ®é›†å’Œé¢„æµ‹é•¿åº¦çš„å®éªŒ
        
        Args:
            dataset_name: æ•°æ®é›†åç§°
            pred_len: é¢„æµ‹é•¿åº¦
            
        Returns:
            å®éªŒç»“æœå­—å…¸
        """
        self.logger.info(f"å¼€å§‹å®éªŒ: {dataset_name} - é¢„æµ‹é•¿åº¦ {pred_len}")
        
        try:
            # ç”Ÿæˆé…ç½®
            config = self.generate_autoformer_config(dataset_name, pred_len)
            
            # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            data_path = config['data']['data_path']
            if not os.path.exists(data_path):
                self.logger.error(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
                return {'error': f'æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}'}
            
            self.logger.info(f"âœ… æ•°æ®æ–‡ä»¶æ‰¾åˆ°: {data_path}")
            
            # åˆ›å»ºè®­ç»ƒå™¨
            trainer = M2MOEPTrainer(config)
            
            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = time.time()
            
            # è®­ç»ƒæ¨¡å‹
            self.logger.info(f"ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹...")
            trainer.train()
            
            # è®¡ç®—è®­ç»ƒæ—¶é—´
            training_time = time.time() - start_time
            
            # è·å–æœ€ä½³éªŒè¯ç»“æœ
            best_val_loss = trainer.best_val_loss
            final_metrics = trainer.training_history['metrics'][-1] if trainer.training_history['metrics'] else {}
            
            # æ•´ç†å®éªŒç»“æœ
            result = {
                'dataset': dataset_name,
                'prediction_length': pred_len,
                'training_time': training_time,
                'best_val_loss': best_val_loss,
                'final_metrics': final_metrics,
                'config': config,
                'model_params': sum(p.numel() for p in trainer.model.parameters()),
                'status': 'success'
            }
            
            self.logger.info(f"âœ… å®éªŒå®Œæˆ: {dataset_name}_{pred_len}")
            self.logger.info(f"   - è®­ç»ƒæ—¶é—´: {training_time:.2f}s")
            self.logger.info(f"   - æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}")
            self.logger.info(f"   - æœ€ç»ˆæŒ‡æ ‡: {final_metrics}")
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ å®éªŒå¤±è´¥: {dataset_name}_{pred_len}")
            self.logger.error(f"   é”™è¯¯ä¿¡æ¯: {str(e)}")
            import traceback
            self.logger.error(f"   è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            
            return {
                'dataset': dataset_name,
                'prediction_length': pred_len,
                'error': str(e),
                'status': 'failed'
            }
    
    def run_all_experiments(self, selected_datasets: List[str] = None, 
                          selected_pred_lens: List[int] = None) -> Dict:
        """
        è¿è¡Œæ‰€æœ‰å®éªŒ
        
        Args:
            selected_datasets: é€‰æ‹©çš„æ•°æ®é›†åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºæ‰€æœ‰æ•°æ®é›†
            selected_pred_lens: é€‰æ‹©çš„é¢„æµ‹é•¿åº¦åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºæ‰€æœ‰é¢„æµ‹é•¿åº¦
            
        Returns:
            æ‰€æœ‰å®éªŒç»“æœ
        """
        datasets = selected_datasets or list(self.autoformer_datasets.keys())
        pred_lens = selected_pred_lens or self.prediction_lengths
        
        total_experiments = len(datasets) * len(pred_lens)
        current_experiment = 0
        
        self.logger.info(f"ğŸ“Š è®¡åˆ’è¿è¡Œ {total_experiments} ä¸ªå®éªŒ")
        self.logger.info(f"   - æ•°æ®é›†: {datasets}")
        self.logger.info(f"   - é¢„æµ‹é•¿åº¦: {pred_lens}")
        
        all_results = {}
        
        for dataset_name in datasets:
            all_results[dataset_name] = {}
            
            for pred_len in pred_lens:
                current_experiment += 1
                self.logger.info(f"\n{'='*60}")
                self.logger.info(f"å®éªŒè¿›åº¦: {current_experiment}/{total_experiments}")
                self.logger.info(f"å½“å‰å®éªŒ: {dataset_name} - é¢„æµ‹é•¿åº¦ {pred_len}")
                self.logger.info(f"{'='*60}")
                
                # è¿è¡Œå®éªŒ
                result = self.run_single_experiment(dataset_name, pred_len)
                all_results[dataset_name][pred_len] = result
                
                # ä¿å­˜ä¸­é—´ç»“æœ
                self.save_results(all_results)
                
                self.logger.info(f"âœ… å®éªŒ {current_experiment}/{total_experiments} å®Œæˆ")
        
        self.all_results = all_results
        return all_results
    
    def save_results(self, results: Dict = None):
        """ä¿å­˜å®éªŒç»“æœ"""
        if results is None:
            results = self.all_results
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        results_file = os.path.join(self.results_dir, f'detailed_results_{timestamp}.json')
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False, default=str)
        
        # ç”Ÿæˆç»“æœæ±‡æ€»è¡¨
        self.generate_results_summary(results)
        
        self.logger.info(f"ğŸ“Š ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    
    def generate_results_summary(self, results: Dict):
        """ç”Ÿæˆç»“æœæ±‡æ€»è¡¨"""
        summary_data = []
        
        for dataset_name, dataset_results in results.items():
            for pred_len, result in dataset_results.items():
                if result.get('status') == 'success':
                    metrics = result.get('final_metrics', {})
                    summary_data.append({
                        'Dataset': dataset_name,
                        'Pred_Len': pred_len,
                        'MSE': metrics.get('MSE', 'N/A'),
                        'MAE': metrics.get('MAE', 'N/A'),
                        'RMSE': metrics.get('RMSE', 'N/A'),
                        'R2': metrics.get('R2', 'N/A'),
                        'Training_Time': f"{result.get('training_time', 0):.2f}s",
                        'Model_Params': result.get('model_params', 0),
                        'Best_Val_Loss': f"{result.get('best_val_loss', 0):.6f}"
                    })
                else:
                    summary_data.append({
                        'Dataset': dataset_name,
                        'Pred_Len': pred_len,
                        'MSE': 'FAILED',
                        'MAE': 'FAILED',
                        'RMSE': 'FAILED',
                        'R2': 'FAILED',
                        'Training_Time': 'FAILED',
                        'Model_Params': 'FAILED',
                        'Best_Val_Loss': 'FAILED'
                    })
        
        # ä¿å­˜ä¸ºCSV
        summary_df = pd.DataFrame(summary_data)
        summary_file = os.path.join(self.results_dir, 'results_summary.csv')
        summary_df.to_csv(summary_file, index=False)
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        self.generate_markdown_report(summary_df)
        
        self.logger.info(f"ğŸ“ˆ ç»“æœæ±‡æ€»å·²ä¿å­˜åˆ°: {summary_file}")
    
    def generate_markdown_report(self, summary_df: pd.DataFrame):
        """ç”ŸæˆMarkdownæ ¼å¼çš„å®éªŒæŠ¥å‘Š"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        markdown_content = f"""# MÂ²-MOEP vs Autoformer æ€§èƒ½æ¯”è¾ƒæŠ¥å‘Š

**å®éªŒæ—¶é—´**: {timestamp}  
**å®éªŒæè¿°**: åŸºäºAutoformerè®ºæ–‡æ ‡å‡†æ•°æ®é›†å’Œå®éªŒè®¾ç½®çš„æ€§èƒ½æ¯”è¾ƒ

## å®éªŒè®¾ç½®

- **è¾“å…¥åºåˆ—é•¿åº¦**: {self.input_length}
- **é¢„æµ‹é•¿åº¦**: {', '.join(map(str, self.prediction_lengths))}
- **æ•°æ®é›†**: {', '.join(self.autoformer_datasets.keys())}
- **è¯„ä¼°æŒ‡æ ‡**: MSE, MAE, RMSE, RÂ²

## è¯¦ç»†ç»“æœ

### æŒ‰æ•°æ®é›†åˆ†ç»„çš„ç»“æœ

"""
        
        # æŒ‰æ•°æ®é›†åˆ†ç»„æ˜¾ç¤ºç»“æœ
        for dataset in summary_df['Dataset'].unique():
            dataset_data = summary_df[summary_df['Dataset'] == dataset]
            markdown_content += f"\n#### {dataset}\n\n"
            markdown_content += "| é¢„æµ‹é•¿åº¦ | MSE | MAE | RMSE | RÂ² | è®­ç»ƒæ—¶é—´ | å‚æ•°é‡ |\n"
            markdown_content += "|---------|-----|-----|------|----|---------|---------|\n"
            
            for _, row in dataset_data.iterrows():
                # å¤„ç†å‚æ•°æ ¼å¼åŒ–
                model_params = row['Model_Params']
                if isinstance(model_params, str) and model_params == 'FAILED':
                    model_params_str = 'FAILED'
                else:
                    model_params_str = f"{model_params:,}"
                
                markdown_content += f"| {row['Pred_Len']} | {row['MSE']} | {row['MAE']} | {row['RMSE']} | {row['R2']} | {row['Training_Time']} | {model_params_str} |\n"
        
        markdown_content += """

## ç»“è®º

æœ¬å®éªŒæŒ‰ç…§Autoformerè®ºæ–‡çš„æ ‡å‡†è®¾ç½®è¿›è¡Œï¼Œå¯ä»¥ç›´æ¥ä¸Autoformerçš„å‘è¡¨ç»“æœè¿›è¡Œæ¯”è¾ƒã€‚

### å…³é”®å‘ç°

1. **æ¨¡å‹æ€§èƒ½**: MÂ²-MOEPåœ¨ä¸åŒæ•°æ®é›†å’Œé¢„æµ‹é•¿åº¦ä¸Šçš„è¡¨ç°
2. **è®­ç»ƒæ•ˆç‡**: è®­ç»ƒæ—¶é—´å’Œæ”¶æ•›æ€§èƒ½
3. **æ¨¡å‹å¤æ‚åº¦**: å‚æ•°é‡å’Œè®¡ç®—å¤æ‚åº¦

### ä¸Autoformeræ¯”è¾ƒ

è¯·å°†ä¸Šè¿°ç»“æœä¸Autoformerè®ºæ–‡ä¸­æŠ¥å‘Šçš„ç»“æœè¿›è¡Œæ¯”è¾ƒåˆ†æã€‚

---
*æœ¬æŠ¥å‘Šç”±MÂ²-MOEPè‡ªåŠ¨åŒ–å®éªŒç³»ç»Ÿç”Ÿæˆ*
"""
        
        # ä¿å­˜MarkdownæŠ¥å‘Š
        report_file = os.path.join(self.results_dir, 'autoformer_comparison_report.md')
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        
        self.logger.info(f"ğŸ“‘ MarkdownæŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='MÂ²-MOEP vs Autoformer æ€§èƒ½æ¯”è¾ƒå®éªŒ')
    parser.add_argument('--datasets', nargs='+', 
                       choices=['ETTh1', 'ETTh2', 'ETTm1', 'ETTm2', 'Weather', 'Electricity', 'Traffic', 'Exchange', 'ILI'],
                       help='é€‰æ‹©è¦è¿è¡Œçš„æ•°æ®é›†')
    parser.add_argument('--pred-lens', nargs='+', type=int, 
                       choices=[96, 192, 336, 720],
                       help='é€‰æ‹©è¦è¿è¡Œçš„é¢„æµ‹é•¿åº¦')
    parser.add_argument('--quick-test', action='store_true',
                       help='å¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼ˆä»…è¿è¡Œéƒ¨åˆ†å®éªŒï¼‰')
    
    args = parser.parse_args()
    
    # åˆ›å»ºå®éªŒç®¡ç†å™¨
    experiment = AutoformerComparisonExperiment()
    
    # ç¡®å®šè¿è¡Œçš„å®éªŒ
    if args.quick_test:
        # å¿«é€Ÿæµ‹è¯•ï¼šåªè¿è¡ŒWeatheræ•°æ®é›†çš„96é¢„æµ‹é•¿åº¦
        selected_datasets = ['Weather']
        selected_pred_lens = [96]
        experiment.logger.info("ğŸš€ å¿«é€Ÿæµ‹è¯•æ¨¡å¼")
    else:
        selected_datasets = args.datasets
        selected_pred_lens = args.pred_lens
    
    try:
        # è¿è¡Œæ‰€æœ‰å®éªŒ
        results = experiment.run_all_experiments(selected_datasets, selected_pred_lens)
        
        # ä¿å­˜æœ€ç»ˆç»“æœ
        experiment.save_results(results)
        
        experiment.logger.info("ğŸ‰ æ‰€æœ‰å®éªŒå®Œæˆï¼")
        experiment.logger.info(f"ğŸ“Š ç»“æœä¿å­˜åœ¨: {experiment.results_dir}")
        
    except KeyboardInterrupt:
        experiment.logger.info("âš ï¸ å®éªŒè¢«ç”¨æˆ·ä¸­æ–­")
        experiment.save_results()
    except Exception as e:
        experiment.logger.error(f"âŒ å®éªŒè¿‡ç¨‹å‡ºç°é”™è¯¯: {e}")
        import traceback
        experiment.logger.error(traceback.format_exc())
        return 1
    
    return 0


if __name__ == '__main__':
    main() 